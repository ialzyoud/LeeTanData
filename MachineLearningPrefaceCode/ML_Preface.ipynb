{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries we will need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining number of data points\n",
    "NUM_SAMPLES = 200\n",
    "\n",
    "#Simulating data. x1 is random from 0 to 1\n",
    "x1 = np.random.rand(NUM_SAMPLES)\n",
    "#x2 is very correlated to x1, with small random fluctuations\n",
    "x2 = x1 + np.random.rand(NUM_SAMPLES)/10\n",
    "\n",
    "#x3-5 are random\n",
    "x3 = np.random.rand(NUM_SAMPLES)\n",
    "x4 = np.random.rand(NUM_SAMPLES)\n",
    "x5 = np.random.rand(NUM_SAMPLES)\n",
    "\n",
    "#y is generated by x1 - x2/2 + noise\n",
    "y = x1 - x2/2 + np.random.rand(NUM_SAMPLES)/10\n",
    "\n",
    "#Lets pack it all into a data frame. A data frame is similar to a SQL table, displayed below\n",
    "df = pd.DataFrame({'x1':x1, 'x2':x2,'x3':x3,'x4':x4,'x5':x5, 'y':y})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is the input features. Think of these like marketing spend by day\n",
    "X = df[['x1', 'x2', 'x3', 'x4', 'x5']]\n",
    "#Y is the target variable. Think of this like the sales by day, as a function of marketing spend\n",
    "Y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets visualize the correlations between x1 vs Y and x2 vs Y\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1).scatter(x1,Y)\n",
    "plt.title('x1 vs Y\\n correlation:' + str(np.corrcoef(x1, Y)[0,1].round(4)))\n",
    "plt.subplot(1,2,2).scatter(x2,Y)\n",
    "plt.title('x2 vs Y\\n correlation:' + str(np.corrcoef(x2, Y)[0,1].round(4)))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we build a regression model using sklearn Ridge and fit it to our dataset\n",
    "RegressionModel = Ridge(1e-3).fit(X,Y)\n",
    "\n",
    "#The coefficients are the ROI of each input feature on our output target\n",
    "coefs = RegressionModel.coef_.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regression coefficients from Sklearn')\n",
    "print(list(zip(['x1', 'x2', 'x3', 'x4', 'x5'], coefs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Below we solve the same problem using tensorflow. Note the significant added complexity to perform the same task\n",
    "# The reason for using tensorflow as opposed to sklearn will come up later, in that it gives us added control\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# We define our inputs\n",
    "x_ph = tf.placeholder(tf.float32, (None, 5))\n",
    "y_ph = tf.placeholder(tf.float32, (None))\n",
    "\n",
    "#We define a linear regression layer\n",
    "yhat = tf.layers.dense(x_ph, 1, name='regression_coefficients')\n",
    "\n",
    "#we calculate our loss\n",
    "loss = tf.reduce_mean(tf.square(yhat[:,0] - y_ph))\n",
    "\n",
    "#We minimize the loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(.1).minimize(loss)\n",
    "\n",
    "#Tensorflow necessary initialization of our model.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#We take optimization steps training the model to fit X, Y\n",
    "for i in range(4000):\n",
    "    sess.run(optimizer, {x_ph:X, y_ph:Y})\n",
    "    \n",
    "#We analyze the regression coefficients (ROI) the model learned\n",
    "with tf.variable_scope(\"regression_coefficients\", reuse=True):\n",
    "    weights = tf.get_variable(\"kernel\")\n",
    "print('Regression coefficients From Tensorflow:')\n",
    "\n",
    "coefs = sess.run(weights[:,0]).round(2)\n",
    "print(list(zip(['x1', 'x2', 'x3', 'x4', 'x5'], coefs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we solve the same problem using tensorflow. Note the significant added complexity to perform the same task\n",
    "# The reason for using tensorflow as opposed to sklearn will come up later, in that it gives us added control\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# We define our inputs\n",
    "x_ph = tf.placeholder(tf.float32, (None, 5))\n",
    "y_ph = tf.placeholder(tf.float32, (None))\n",
    "\n",
    "#We define a linear regression layer\n",
    "yhat = tf.layers.dense(x_ph, 1, name='regression_coefficients')\n",
    "\n",
    "#we calculate our loss\n",
    "loss = tf.reduce_mean(tf.square(yhat[:,0] - y_ph))\n",
    "\n",
    "#We minimize the loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(.1).minimize(loss)\n",
    "\n",
    "#Tensorflow necessary initialization of our model.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "with tf.variable_scope(\"regression_coefficients\", reuse=True):\n",
    "    weights = tf.get_variable(\"kernel\")\n",
    "\n",
    "loss_achieved = 0\n",
    "ROI_achieved = 0\n",
    "GT = np.array([1,-.5,0,0,0])\n",
    "#We take optimization steps training the model to fit X, Y\n",
    "for i in range(4000):\n",
    "    sess.run(optimizer, {x_ph:X, y_ph:Y})\n",
    "    lossval = sess.run(loss, {x_ph:X, y_ph:Y})\n",
    "    if lossval < .011 and not loss_achieved:\n",
    "        print('Loss Achieved', i)\n",
    "        loss_achieved = 1\n",
    "    if i % 1000 == 0:\n",
    "        coefs = sess.run(weights[:,0]).round(2)\n",
    "        if (GT - coefs < .1).all() and not ROI_achieved:\n",
    "            print('ROI Achieved', i)\n",
    "            ROI_achieved = 1\n",
    "    if loss_achieved and ROI_achieved:\n",
    "        break\n",
    "    \n",
    "#We analyze the regression coefficients (ROI) the model learned\n",
    "with tf.variable_scope(\"regression_coefficients\", reuse=True):\n",
    "    weights = tf.get_variable(\"kernel\")\n",
    "print('Regression coefficients From Tensorflow:')\n",
    "\n",
    "coefs = sess.run(weights[:,0]).round(2)\n",
    "print(list(zip(['x1', 'x2', 'x3', 'x4', 'x5'], coefs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossval\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
