{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "pd.set_option(\"display.max_columns\",200)\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Super upgraded walk forward optimization\n",
    "#TODO: Data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ListingsAndSales.csv')\n",
    "#not sold flag\n",
    "df['NotSoldFlag'] = 0\n",
    "df.loc[df['SalesDate'].isnull() == True,'NotSoldFlag'] = 1\n",
    "\n",
    "#convert ListingDate and SalesDate to date\n",
    "df.ListingDate = pd.to_datetime(df.ListingDate)\n",
    "\n",
    "df.SalesDate = df.SalesDate.fillna('2015-04-07')\n",
    "df.SalesDate = pd.to_datetime(df.SalesDate)\n",
    "\n",
    "#calculate days it took to sell the listing if it's sold\n",
    "df['DaysSold'] = (df.SalesDate - df.ListingDate).dt.days.astype(float)\n",
    "#add one to DaysSold to prevent 0 when taking the log afterwards\n",
    "df['DaysSold'] = df['DaysSold'] + 1\n",
    "\n",
    "#loop through the variables and replace missing values with avg and create dummy variables\n",
    "col_dates = ['ListingDate', 'SalesDate']\n",
    "for i in df.columns.values:\n",
    "    if not i in col_dates:\n",
    "        if df[i].isnull().sum(axis = 0) > 0:\n",
    "            avg_i = df[i][df[i].isnull() == False].mean()\n",
    "            df[i + \"_mv\"] = (df[i].isnull())*1\n",
    "            df[i] = df[i].fillna(avg_i)\n",
    "\n",
    "#convert ListingDate to the day of the year, since all the dates are within a year\n",
    "df['ListingDay'] = (df.ListingDate - df.ListingDate.min()).dt.days\n",
    "\n",
    "#drop SalesDate variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data into Training Set and Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6864035087719298"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NotSoldFlag'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['DaysSold', 'ListingDate', 'SalesDate', 'NotSoldFlag'],axis = 1)\n",
    "Y = df[['DaysSold']].as_matrix().astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = X.columns).as_matrix().astype(np.float32)\n",
    "sold = df['NotSoldFlag'].as_matrix().astype(np.float32)\n",
    "\n",
    "n_samples = Y.shape[0]\n",
    "n_features = X.shape[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_clipped_optimizer(opt_fcn,\n",
    "                            loss,\n",
    "                            clip_norm=.1,\n",
    "                            clip_single=.03,\n",
    "                            clip_global_norm=False):\n",
    "  gvs = opt_fcn.compute_gradients(loss)\n",
    "\n",
    "  if clip_global_norm:\n",
    "    gs, vs = zip(*[(g, v) for g, v in gvs if g is not None])\n",
    "    capped_gs, grad_norm_total = tf.clip_by_global_norm([g for g in gs],\n",
    "                                                        clip_norm)\n",
    "    capped_gvs = list(zip(capped_gs, vs))\n",
    "  else:\n",
    "    grad_norm_total = tf.sqrt(\n",
    "        tf.reduce_sum([\n",
    "            tf.reduce_sum(tf.square(grad)) for grad, var in gvs\n",
    "            if grad is not None\n",
    "        ]))\n",
    "    capped_gvs = [(tf.clip_by_value(grad, -1 * clip_single, clip_single), var)\n",
    "                  for grad, var in gvs if grad is not None]\n",
    "    capped_gvs = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                  for grad, var in capped_gvs if grad is not None]\n",
    "\n",
    "  optimizer = opt_fcn.apply_gradients(\n",
    "      capped_gvs, global_step=tf.train.get_global_step())\n",
    "\n",
    "  return optimizer, grad_norm_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For numeric stability\n",
    "EPSILON = 1e-10\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, input_size, layer_sizes):\n",
    "        self.input_size = input_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.sold = tf.placeholder(tf.float32, shape = (None))\n",
    "        self.x = tf.placeholder(tf.float32, shape=(None, input_size))\n",
    "        self.y = tf.placeholder(tf.float32, shape=(None))\n",
    "        self.layers = [self.x]\n",
    "        for layer_size in layer_sizes:\n",
    "            next_layer = tf.nn.leaky_relu(tf.layers.dense(self.layers[-1], layer_size))\n",
    "            self.layers.append(next_layer)\n",
    "        self.output = tf.nn.softplus(tf.layers.dense(self.layers[-1], 1))\n",
    "        \n",
    "        self.loss_indicator = (tf.cast(self.output < self.y, tf.float32) * (1-self.sold) + self.sold)\n",
    "        loss_numerator = tf.reduce_sum(tf.square(self.y - self.output) * self.loss_indicator)\n",
    "        loss_denominator = (tf.reduce_sum(self.loss_indicator)) + EPSILON\n",
    "        self.loss = loss_numerator/loss_denominator\n",
    "        opt_fcn = tf.train.AdamOptimizer()\n",
    "        self.optimizer = apply_clipped_optimizer(opt_fcn, self.loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train loss:  1213.85 val loss:  1121.11\n",
      "epoch: 10 train loss:  69.3238 val loss:  66.347\n",
      "epoch: 20 train loss:  51.2745 val loss:  50.1268\n",
      "epoch: 30 train loss:  45.0404 val loss:  44.7469\n",
      "epoch: 40 train loss:  41.9306 val loss:  41.5839\n",
      "epoch: 50 train loss:  38.9849 val loss:  39.1433\n",
      "epoch: 60 train loss:  37.4565 val loss:  37.087\n",
      "epoch: 70 train loss:  35.8448 val loss:  35.8651\n",
      "epoch: 80 train loss:  35.5389 val loss:  34.2937\n",
      "epoch: 90 train loss:  34.9963 val loss:  33.6411\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tf.reset_default_graph()      \n",
    "        \n",
    "model = Model(n_features, layer_sizes = [32, 32,])\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "X_test = X_train = X\n",
    "Y_train = Y_test = Y\n",
    "sold_train = sold_test = sold\n",
    "trn_losses = []\n",
    "val_losses = []\n",
    "r2_scores = []\n",
    "bs=64\n",
    "num_batches = (n_samples // bs) + 1\n",
    "for epoch in range(100):\n",
    "    trn_loss = []\n",
    "    order = np.arange(n_samples)\n",
    "    np.random.shuffle(order)\n",
    "    for itr in range(n_samples//bs):\n",
    "        rows = order[itr*bs:(itr+1)*bs]\n",
    "        if itr+1 == num_batches:\n",
    "            rows = order[itr*bs:]\n",
    "        X_active, Y_active, Sold_active = X_train[rows,:], Y_train[rows], sold_train[rows]\n",
    "        feed_dict = {model.x: X_active,\n",
    "                model.y: Y_active,\n",
    "                model.sold: Sold_active}\n",
    "        _, loss, yhat = sess.run([model.optimizer, model.loss, model.output], feed_dict)\n",
    "        trn_loss.append(loss)\n",
    "    if epoch % 2 == 0:\n",
    "        trn_loss_mean = np.mean(trn_loss)\n",
    "        trn_losses.append(trn_loss_mean)\n",
    "        feed_dict = {model.x: X_test,\n",
    "                    model.y: Y_test,\n",
    "                    model.sold: sold_test}\n",
    "        val_loss, yhat = sess.run([model.loss, model.output], feed_dict)\n",
    "        val_losses.append(val_loss)\n",
    "        r2_scores.append(r2_score(Y_test, yhat))\n",
    "    if epoch % 10 == 0:\n",
    "        print( 'epoch:', epoch, 'train loss: ', trn_loss_mean, 'val loss: ',val_loss)\n",
    "y_tst_predict = sess.run(model.output, {model.x: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM4cPm9KBZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe76fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpZTDgAzs5z6/zFCu6r5+BBoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xefb1400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trn_losses, label = 'train loss')\n",
    "plt.plot(val_losses, label = 'test loss')\n",
    "plt.title('least square losses')\n",
    "plt.show()\n",
    "plt.plot(r2_scores, label='validation r2_scores')\n",
    "plt.title('r2 scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListingDate</th>\n",
       "      <th>SalesDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4104</td>\n",
       "      <td>4104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>98</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2015-04-03 00:00:00</td>\n",
       "      <td>2015-04-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>125</td>\n",
       "      <td>2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2014-12-31 00:00:00</td>\n",
       "      <td>2015-01-12 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>2015-04-07 00:00:00</td>\n",
       "      <td>2015-04-07 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ListingDate            SalesDate\n",
       "count                  4104                 4104\n",
       "unique                   98                   34\n",
       "top     2015-04-03 00:00:00  2015-04-07 00:00:00\n",
       "freq                    125                 2817\n",
       "first   2014-12-31 00:00:00  2015-01-12 00:00:00\n",
       "last    2015-04-07 00:00:00  2015-04-07 00:00:00"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ListingDate', 'SalesDate']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_active' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e6da02fd61f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_active\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DaysSold'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ListingDate'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SalesDate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_active\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DaysSold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_active' is not defined"
     ]
    }
   ],
   "source": [
    "X = df_active.drop(['DaysSold', 'ListingDate', 'SalesDate'],axis = 1)\n",
    "Y = df_active[['DaysSold']]\n",
    "\n",
    "n_samples = Y.shape[0]\n",
    "train_size = n_samples * 3 // 4 \n",
    "X_train, Y_train = [df.iloc]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size = 0.75)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "#for neural network\n",
    "Y_nn = pd.DataFrame(df['DaysSold'])\n",
    "X_train_nn, X_test_nn, Y_train_nn, Y_test_nn = train_test_split(X, Y_nn, train_size = 0.75)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_nn = pd.DataFrame(scaler.fit_transform(X_train_nn), columns = X_train.columns)\n",
    "X_test_scaled_nn = pd.DataFrame(scaler.transform(X_test_nn), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run linear regression\n",
    "linear = LinearRegression().fit(X_train_scaled, Y_train)\n",
    "linear_pred_test = np.exp(linear.predict(X_test_scaled)) - 1\n",
    "linear_pred_train = np.exp(linear.predict(X_train_scaled)) - 1\n",
    "\n",
    "#customized evaluation metrics\n",
    "#when Y is larger than DaysSold, no error\n",
    "X_train_linear_pred = pd.merge(X_train_scaled, pd.DataFrame(linear_pred_train, columns = ['Y'], index = X_train_scaled.index), how = 'inner', left_index= True, right_index = True)\n",
    "X_train_linear_pred = pd.merge(X_train_linear_pred, pd.DataFrame(df['DaysSold']), how = 'inner', left_index = True, right_index = True)\n",
    "\n",
    "X_train_linear_pred['Err_Val'] = np.square(X_train_linear_pred['DaysSold'] - X_train_linear_pred['Y'])\n",
    "X_train_linear_pred['Err_Ind'] = (X_train_linear_pred['NotSoldFlag'] == 0) + ((X_train_linear_pred['NotSoldFlag'] == 1) + (X_train_linear_pred['Y'] <= X_train_linear_pred['DaysSold']))\n",
    "X_train_linear_pred['Eval'] = X_train_linear_pred['Err_Val'] * X_train_linear_pred['Err_Ind']\n",
    "linear_mse_train = X_train_linear_pred['Eval'].mean()\n",
    "\n",
    "\n",
    "X_test_linear_pred = pd.merge(X_test_scaled, pd.DataFrame(linear_pred_test, columns = ['Y'], index = X_test_scaled.index), how = 'inner', left_index= True, right_index = True)\n",
    "X_test_linear_pred = pd.merge(X_test_linear_pred, pd.DataFrame(df['DaysSold']), how = 'inner', left_index = True, right_index = True)\n",
    "\n",
    "X_test_linear_pred['Err_Val'] = np.square(X_test_linear_pred['DaysSold'] - X_test_linear_pred['Y'])\n",
    "X_test_linear_pred['Err_Ind'] = (X_test_linear_pred['NotSoldFlag'] == 0) + \\\n",
    "    ((X_test_linear_pred['NotSoldFlag'] == 1) + (X_test_linear_pred['Y'] <= X_test_linear_pred['DaysSold']))\n",
    "X_test_linear_pred['Eval'] = X_test_linear_pred['Err_Val'] * X_test_linear_pred['Err_Ind']\n",
    "linear_mse_test = X_test_linear_pred['Eval'].mean()\n",
    "\n",
    "print('Mean squared error for linear regression on train set is {}.'.format(linear_mse_train))\n",
    "print('Mean squared error for linear regression on test set is {}.'.format(linear_mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_scaled_features = X_train_scaled_nn.drop(['NotSoldFlag'], axis = 1)\n",
    "X_test_scaled_features = X_test_scaled_nn.drop(['NotSoldFlag'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run neural network with customized one-sided loss function\n",
    "def lrelu(x):\n",
    "    return tf.maximum(x, 1e-1*x)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, input_size, layer_sizes):\n",
    "        self.input_size = input_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.sold = tf.placeholder(tf.float32, shape = (None))\n",
    "        self.input_layer = tf.placeholder(tf.float32, shape=(None, input_size))\n",
    "        self.y = tf.placeholder(tf.float32, shape=(None))\n",
    "        prev_layer = self.input_layer/10\n",
    "        for idx, layer in enumerate(layer_sizes):\n",
    "            next_layer = tf.layers.dense(prev_layer, layer, name='layer'+str(idx))\n",
    "            prev_layer = lrelu(next_layer)\n",
    "        self.output = tf.nn.softplus(tf.layers.dense(prev_layer, 1, name='output'))\n",
    "        \n",
    "        self.loss_indicator = (tf.cast(self.output < self.y, tf.float32) * (1-self.sold) + self.sold) + 1e-8\n",
    "        \n",
    "        self.loss = tf.reduce_sum(tf.square(self.y - self.output) * self.loss_indicator) / (tf.reduce_sum(self.loss_indicator))\n",
    "        grad_clipping = 0\n",
    "        if grad_clipping:\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "            gvs = optimizer.compute_gradients(self.loss)\n",
    "            self.grad_norm = tf.reduce_mean([tf.reduce_mean(tf.square(grad)) for grad, var in gvs if grad is not None])\n",
    "            clip_norm = 100\n",
    "            clip_single = 1\n",
    "            capped_gvs = [(tf.clip_by_value(grad, -1*clip_single,clip_single), var)\n",
    "                          for grad, var in gvs if grad is not None]\n",
    "            capped_gvs = [(tf.clip_by_norm(grad, clip_norm), var) for grad, var in capped_gvs if grad is not None]\n",
    "            self.optimizer = optimizer.apply_gradients(capped_gvs)\n",
    "        else:\n",
    "            self.grad_norm = 'NotUsed'\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(self.loss)\n",
    "        \n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "model = Model(X_train_scaled_features.shape[1], layer_sizes = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "101 // 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_trn, Y_trn = X_train_scaled_features.as_matrix().astype(np.float32), Y_train_nn.as_matrix().astype(np.float32)\n",
    "X_tst, Y_tst = X_test_scaled_features.as_matrix().astype(np.float32), Y_test_nn.as_matrix().astype(np.float32)\n",
    "sold = X_train['NotSoldFlag'].as_matrix().astype(np.float32)\n",
    "sold_tst = X_test['NotSoldFlag'].as_matrix().astype(np.float32)\n",
    "trn_loss = []\n",
    "num_rows = X_trn.shape[0]\n",
    "bs=100\n",
    "num_batches = (num_rows // bs) + 1\n",
    "for epoch in range(100):\n",
    "    order = np.arange(num_rows)\n",
    "    np.random.shuffle(order)\n",
    "    for itr in range(num_rows//bs):\n",
    "        rows = order[itr*bs:(itr+1)*bs]\n",
    "        if itr+1 == num_batches:\n",
    "            rows = order[itr*bs:]\n",
    "        X_active, Y_active, Sold_active = X_trn[rows,:], Y_trn[rows], sold[rows]\n",
    "        feed_dict = {model.input_layer: X_active,\n",
    "                model.y: Y_active,\n",
    "                model.sold: Sold_active}\n",
    "        _, loss, yhat = model.sess.run([model.optimizer, model.loss, model.output], feed_dict)\n",
    "        trn_loss.append(loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print('train loss: ',np.mean(trn_loss), 'epoch:', epoch)\n",
    "        trn_loss = []\n",
    "        feed_dict = {model.input_layer: X_tst,\n",
    "                    model.y: Y_tst,\n",
    "                    model.sold: sold_tst}\n",
    "        val_loss = model.sess.run(model.loss, feed_dict)\n",
    "        print('val loss: ',val_loss, 'itr:', itr)\n",
    "y_tst_predict = model.sess.run(model.output, {model.input_layer: X_tst})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tst_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
