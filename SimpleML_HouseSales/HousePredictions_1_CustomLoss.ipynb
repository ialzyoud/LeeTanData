{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import os\n",
    "\n",
    "imagedir = 'images'\n",
    "if not os.path.isdir(imagedir):\n",
    "    os.mkdir(imagedir)\n",
    "# For numeric stability\n",
    "EPSILON = 1e-10\n",
    "\n",
    "df = pd.read_csv('ListingsAndSales.csv')\n",
    "\n",
    "# not sold flag\n",
    "df['NotSoldFlag'] = 0\n",
    "df.loc[df['SalesDate'].isnull() == True, 'NotSoldFlag'] = 1\n",
    "print('percent not yet sold:', df['NotSoldFlag'].mean())\n",
    "\n",
    "df.ListingDate, df.SalesDate = [\n",
    "    pd.to_datetime(col) for col in [df.ListingDate, df.SalesDate]\n",
    "]\n",
    "df.SalesDate = df.SalesDate.fillna(df.SalesDate.max())\n",
    "\n",
    "# Get day of dataset for each sample\n",
    "df['ListingDay'] = (df.ListingDate - df.ListingDate.min()).dt.days\n",
    "df = df.sort_values('ListingDay')\n",
    "\n",
    "# calculate days it took to sell the listing if it's sold\n",
    "df['DaysSold'] = (df.SalesDate - df.ListingDate).dt.days.astype(float) + 1\n",
    "\n",
    "# loop through the variables and replace missing values with avg and create dummy variables\n",
    "col_dates = ['ListingDate', 'SalesDate']\n",
    "for col in df.columns:\n",
    "    if not col in col_dates:\n",
    "        if df[col].isnull().sum(axis=0) > 0:\n",
    "            df[col + \"_null_flag\"] = (df[col].isnull())\n",
    "            col_avg = df.loc[df[col].isnull() == False, col].mean()\n",
    "            df[col] = df[col].fillna(col_avg)\n",
    "\n",
    "# Columns to use as regressors\n",
    "X = df.drop(['DaysSold', 'ListingDate', 'SalesDate', 'NotSoldFlag'], axis=1)\n",
    "\n",
    "# Column to use as target\n",
    "Y = df[['DaysSold']].as_matrix().astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(\n",
    "    scaler.fit_transform(X)).as_matrix().astype(np.float32)\n",
    "sold = df['NotSoldFlag'].as_matrix().astype(np.float32)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, input_size, layer_sizes):\n",
    "        self.input_size = input_size\n",
    "        self.layer_sizes = layer_sizes\n",
    "\n",
    "        self.sold = tf.placeholder(tf.float32, shape=(None))\n",
    "        self.x = tf.placeholder(tf.float32, shape=(None, input_size))\n",
    "        self.y = tf.placeholder(tf.float32, shape=(None))\n",
    "\n",
    "        self.layers = [self.x]\n",
    "        for layer_size in layer_sizes:\n",
    "            next_layer = tf.nn.leaky_relu(\n",
    "                tf.layers.dense(self.layers[-1], layer_size))\n",
    "            self.layers.append(next_layer)\n",
    "\n",
    "        self.output = tf.nn.softplus(tf.layers.dense(self.layers[-1], 1))\n",
    "\n",
    "        self.loss_indicator = (tf.cast(self.output < self.y, tf.float32) *\n",
    "                               (1 - self.sold) + self.sold)\n",
    "        loss_numerator = tf.reduce_sum(\n",
    "            tf.square(self.y - self.output) * self.loss_indicator)\n",
    "        loss_denominator = (tf.reduce_sum(self.loss_indicator)) + EPSILON\n",
    "        self.loss = loss_numerator / loss_denominator\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer().minimize(self.loss)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        self.trn_losses = []\n",
    "        self.val_losses = []\n",
    "        self.r2_scores = []\n",
    "\n",
    "    def train_one_epoch(self, trn_samples, bs, X_train, Y_train, sold_train):\n",
    "        # Train an epoch\n",
    "        trn_loss = []\n",
    "        # Randomly shuffle data and prepare for training\n",
    "        order = np.arange(trn_samples)\n",
    "        np.random.shuffle(order)\n",
    "        num_batches = (trn_samples // bs) + 1\n",
    "        for itr in range(trn_samples // bs):\n",
    "            rows = order[itr * bs:(itr + 1) * bs]\n",
    "            if itr + 1 == num_batches:\n",
    "                rows = order[itr * bs:]\n",
    "            X_active, Y_active, Sold_active = [\n",
    "                mat[rows] for mat in [X_train, Y_train, sold_train]\n",
    "            ]\n",
    "            feed_dict = {\n",
    "                self.x: X_active,\n",
    "                self.y: Y_active,\n",
    "                self.sold: Sold_active\n",
    "            }\n",
    "            _, loss = self.sess.run([self.optimizer, self.loss], feed_dict)\n",
    "            trn_loss.append(loss)\n",
    "        self.trn_losses.append(np.mean(trn_loss))\n",
    "\n",
    "    def validate(self, X_test, Y_test, sold_test):\n",
    "        feed_dict = {self.x: X_test, self.y: Y_test, self.sold: sold_test}\n",
    "        val_loss, yhat = self.sess.run([self.loss, self.output], feed_dict)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.r2_scores.append(r2_score(Y_test, yhat))\n",
    "\n",
    "    def train(self, X, Y, sold, epochs):\n",
    "        # Train the model based on X,Y,sold data for a set number of epochs\n",
    "        n_samples = X.shape[0]\n",
    "        trn_samples = (n_samples * 4) // 5\n",
    "        bs = 64\n",
    "        \n",
    "        # Let's randomly split the data here between train and test.\n",
    "        # We will do better in a later version.\n",
    "        samples = np.arange(n_samples)\n",
    "        trn_s = np.random.choice(samples, size=trn_samples, replace=False)\n",
    "        val_samples = [s for s in samples if s not in trn_s]\n",
    "        X_train, X_test = X[trn_s], X[val_samples]\n",
    "        Y_train, Y_test = Y[trn_s], Y[val_samples]\n",
    "        sold_train, sold_test = sold[trn_s], sold[val_samples]\n",
    "\n",
    "        # Everything is set. Now train and validate\n",
    "        for epoch in range(epochs):\n",
    "            # run one epoch train and validation\n",
    "            self.train_one_epoch(trn_samples, bs, X_train, Y_train, sold_train)\n",
    "            self.validate(X_test, Y_test, sold_test)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                # Occasionally print to command line to inspect performance\n",
    "                print('epoch:', epoch, 'train loss: ', self.trn_losses[-1],\n",
    "                      'val loss: ', self.val_losses[-1], 'r2_score:',\n",
    "                      self.r2_scores[-1])\n",
    "\n",
    "    def visualize(self, name):\n",
    "        # Visualize training and validation losses and r2 scores on one plot\n",
    "        _, ax1 = plt.subplots()\n",
    "        ax2 = ax1.twinx()\n",
    "        ax1.plot(self.trn_losses, label='train loss')\n",
    "        ax1.plot(self.val_losses, label='test loss')\n",
    "        ax2.plot(self.r2_scores, label='validation r2_scores', color='g')\n",
    "        ax1.set_xlabel('epochs')\n",
    "        ax1.set_ylabel('least square losses')\n",
    "        ax2.set_ylabel('R2 Scores')\n",
    "        ax2.legend()\n",
    "        ax1.legend()\n",
    "        plt.title('Losses and r2 scores for ' + name)\n",
    "        plt.savefig(imagedir + '/' + name + '.jpg')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_features, layer_sizes=[])\n",
    "model.train(X, Y, sold, epochs=100)\n",
    "model.visualize('linear_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_features, layer_sizes=[64])\n",
    "model.train(X, Y, sold, epochs=100)\n",
    "model.visualize('one_hidden_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_features, layer_sizes=[64, 64])\n",
    "model.train(X, Y, sold, epochs=100)\n",
    "model.visualize('two_hidden_layers')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
