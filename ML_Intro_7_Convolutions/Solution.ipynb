{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 7: Introduction to Convolutional Layers\n",
    "\n",
    "The goal of this lab is to understand how to train a convolutional neural network using PyTorch.\n",
    "\n",
    "The dataset we will analyze will be a small section of the nih chest xrays dataset, found here: https://www.kaggle.com/nih-chest-xrays/sample. The dataset has images of resolution 1024x1024, but to make it computationally easier we have first applied pooling in scipy to reduce the dimensionality to 64x64.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import common dependencies\n",
    "import torch\n",
    "import pandas as pd, numpy as np, matplotlib, matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import PIL, glob\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "from scipy import misc\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we address some of the in class activities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use python to generate the kernels randomly [-1, 0, 1] \n",
    "#and calculate the hidden layer values for the follow input image:\n",
    "inpt = [[2, 1, 0, 0,1],\n",
    "        [0, 0, 0, 1, 0],\n",
    "        [0, 0, 1, 2, 0],\n",
    "        [1, 2, 0, 1, 0],\n",
    "        [0, 1, 0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_kernel_output = {}\n",
    "mat = np.array(inpt)\n",
    "for i in range(1, 4):\n",
    "    for j in range(1, 4):\n",
    "        for k in range(2):\n",
    "            inpt_x = mat[i-1:i+2, j-1:j+2]\n",
    "            kernel = np.random.choice([-1, 0, 1], (3, 3))\n",
    "            output = (inpt_x * kernel).sum()\n",
    "            #apply relu\n",
    "            output = output.clip(0, np.inf)\n",
    "            input_kernel_output[(i, j, k)] = {'input ':inpt_x.tolist(), 'kernel':kernel.tolist(), 'output':output.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(input_kernel_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_kernel_output_parameter_sharing = {}\n",
    "mat = np.array(inpt)\n",
    "np.random.seed(1)\n",
    "for k in range(2):\n",
    "    kernel = np.random.choice([-1, 0, 1], (3, 3))\n",
    "    for i in range(1, 4):\n",
    "        for j in range(1, 4):\n",
    "            inpt_x = mat[i-1:i+2, j-1:j+2]\n",
    "            \n",
    "            output = (inpt_x * kernel).sum()\n",
    "            #apply relu\n",
    "            output = output.clip(0, np.inf)\n",
    "            input_kernel_output_parameter_sharing[(i, j, k)] = {'input ':inpt_x.tolist(), 'kernel':kernel.tolist(), 'output':output.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "pprint(input_kernel_output_parameter_sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Selection\n",
    "\n",
    "### First, read in the sample labels which we will treat as y classes, and split into trn and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv('sample_labels.csv').iloc[:, [1]]\n",
    "label_df.columns = ['label']\n",
    "num_rows = label_df.shape[0]\n",
    "val_frac = .9\n",
    "samples = np.random.rand(num_rows)\n",
    "cutoff = np.percentile(samples, val_frac * 100)\n",
    "trn, val = samples < cutoff, samples >= cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, map labels to unique values, and drop all uncommon labels into a 'unknown' label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "uni_lbls = label_df['label'].value_counts().sort_values(ascending=False)\n",
    "lbls = uni_lbls[uni_lbls > 10]\n",
    "lbl_keys = lbls.keys()\n",
    "num_keys = len(lbl_keys)\n",
    "lbl_idx = np.arange(num_keys)\n",
    "\n",
    "unk = 'unknown/uncommon'\n",
    "\n",
    "lbl_map = {key:idx for key, idx in zip(lbl_keys, lbl_idx)}\n",
    "inv_lbl_map = {idx:key for key, idx in zip(lbl_keys, lbl_idx)}\n",
    "\n",
    "for lbl in label_df['label'].unique():\n",
    "    if lbl not in lbl_map.keys():\n",
    "        lbl_map[lbl] = num_keys\n",
    "label_df['label_idx'] = label_df['label'].map(lbl_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = label_df.loc[trn]\n",
    "val_df = label_df.loc[val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load in the corresponding images, or load in the pre processed numpy array that we use to store them. Lets normalize them to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_file = Path(\"images.pickle\")\n",
    "if not my_file.is_file():\n",
    "    import skimage.measure\n",
    "\n",
    "    images = np.empty((num_rows, 64, 64))\n",
    "    for idx,filename in enumerate(glob.glob('images/*')): #assuming gif\n",
    "        im=misc.imread(filename)\n",
    "        if im.shape[-1] < 5:\n",
    "            im = im[:,:,0]\n",
    "        im = skimage.measure.block_reduce(im, (16,16), np.max)\n",
    "        images[idx,:,:] = im\n",
    "\n",
    "    images = np.reshape(images, [num_rows, 1, 64, 64])\n",
    "    images = images - images.min()\n",
    "    images = images/images.max()\n",
    "    pickle.dump(images, open('images.pickle', 'wb'))\n",
    "else:\n",
    "    images = pickle.load(open('images.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets just visualize an image to see what we're looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_images = images[trn,:,:,:]\n",
    "val_images = images[val,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(trn_images[0,0,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to cleanly swap between Pytorch and Numpy.\n",
    "# Makes PyTorch much more user friendly, but not widely used. \n",
    "\n",
    "#Main adjustable flag. Enables or Disable GPU optimizations\n",
    "USE_CUDA = 1\n",
    "\n",
    "def cuda(obj):\n",
    "    if USE_CUDA:\n",
    "        if isinstance(obj, tuple):\n",
    "            return tuple(cuda(o) for o in obj)\n",
    "        elif isinstance(obj, list):\n",
    "            return list(cuda(o) for o in obj)\n",
    "        elif hasattr(obj, 'cuda'):\n",
    "            return obj.cuda()\n",
    "    return obj\n",
    "\n",
    "def tovar(*arrs, **kwargs):\n",
    "    tensors = [(torch.from_numpy(a) if isinstance(a, np.ndarray) else a) for a in arrs]\n",
    "    vars_ = [torch.autograd.Variable(t, **kwargs) for t in tensors]\n",
    "    if USE_CUDA:\n",
    "        vars_ = [v.cuda() for v in vars_]\n",
    "    return vars_[0] if len(vars_) == 1 else vars_\n",
    "\n",
    "\n",
    "def tonumpy(*vars_):\n",
    "    arrs = [(v.data.cpu().numpy() if isinstance(v, torch.autograd.Variable) else\n",
    "             v.cpu().numpy() if torch.is_tensor(v) else v) for v in vars_]\n",
    "    return arrs[0] if len(arrs) == 1 else arrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the network in pytorch\n",
    "\n",
    "def init_weights(module):\n",
    "    #Optional: Initialize weights using Xavier Initialization \n",
    "    for name, param in module.named_parameters():\n",
    "        if name.find('weight') != -1:\n",
    "            if len(param.size()) == 1:\n",
    "                init.uniform(param.data, 1)\n",
    "            else:\n",
    "                init.xavier_uniform(param.data)\n",
    "        elif name.find('bias') != -1:\n",
    "            init.constant(param.data, 0)\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    #Identity Module\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,input_shape, hidden_layers = None, num_outputs = 1, lr = 1e-3):\n",
    "        #num_inputs is the number of input feature\n",
    "        #Hidden layers is a list of hidden layer sizes)\n",
    "        nn.Module.__init__(self)\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        prev_filters = 1\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        shape = input_shape\n",
    "        self.trn_losses = []\n",
    "        self.val_losses = []\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        if hidden_layers is not None:\n",
    "            for idx, (filters, kernel_size, stride, padding, pool) in enumerate(hidden_layers):\n",
    "                if pool:\n",
    "                    layer = nn.MaxPool2d(kernel_size, stride=stride, padding=padding)\n",
    "                    self.hidden_layers.append(layer)\n",
    "                else:\n",
    "                    layer = nn.Conv2d(in_channels = prev_filters, out_channels = filters, kernel_size = kernel_size, \n",
    "                                  stride=stride, padding=padding)\n",
    "                    self.hidden_layers.append(layer)\n",
    "                    self.hidden_layers.append(self.relu)\n",
    "                    prev_filters = filters\n",
    "                if idx == 0:\n",
    "                    self.first_layer = layer\n",
    "                shape = shape // stride\n",
    "            self.flat_size = prev_filters * shape * shape\n",
    "            self.output_layer = nn.Linear(self.flat_size, num_outputs)\n",
    "        else:\n",
    "            #Optionally: Design your custom network without programmatic interface here!\n",
    "            pass\n",
    "        \n",
    "        self.loss_fcn = nn.CrossEntropyLoss()\n",
    "            \n",
    "        self.optimizer = torch.optim.RMSprop(self.parameters(), lr = lr, weight_decay = 1e-8)\n",
    "        init_weights(self)\n",
    "        print(self.hidden_layers)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        x = tovar(x).float()\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = x.view(-1, self.flat_size)\n",
    "        output = self.output_layer(x)\n",
    "        return output, self.loss_fcn(output, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(trn_images, val_images, trn_df, val_labels, epochs = 3, verbosity = 0, val_freq = 1):\n",
    "    num_epochs = epochs\n",
    "    bs = 128\n",
    "    rows_trn = trn_images.shape[0]\n",
    "    batches_per_epoch = rows_trn // bs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Optimize Model on mini batches\n",
    "        trn_loss = []\n",
    "        order = np.arange(rows_trn)\n",
    "        np.random.shuffle(order)\n",
    "        for itr in range(batches_per_epoch):\n",
    "            rows = order[itr*bs:(itr+1)*bs]\n",
    "            if itr+1 == batches_per_epoch:\n",
    "                rows = order[itr*bs:]\n",
    "            x, y = trn_images[rows,:,:,:], trn_df.iloc[rows, 1].as_matrix()\n",
    "\n",
    "            y_pred, loss = model(x, tovar(y))\n",
    "\n",
    "            # Before the backward pass, use the optimizer object to zero all of the \n",
    "            # gradients for the variables it will update (which are the learnable weights of the model)\n",
    "            model.optimizer.zero_grad()\n",
    "\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # Calling the step function on an Optimizer makes an update to its parameters\n",
    "            model.optimizer.step()\n",
    "            trn_loss.append(tonumpy(loss.data))\n",
    "            if itr % 100 == 0:\n",
    "                print('itr:', itr)\n",
    "        if epoch % val_freq == 0:\n",
    "            #Evaluate Performance on on validation set\n",
    "            trn_loss = np.mean(trn_loss)\n",
    "            model.trn_losses.append(trn_loss)\n",
    "            xval, yval = val_images, val_df.iloc[:, 1].as_matrix()\n",
    "            y_pred, loss = model(xval, tovar(yval))\n",
    "            val_loss = tonumpy(loss.data)\n",
    "            print( 'epoch:', epoch)\n",
    "            print('train loss: ',trn_loss)\n",
    "            print('val loss: ',val_loss)\n",
    "            trn_loss = []\n",
    "            model.val_losses.append(val_loss)\n",
    "def visualize(verbosity = 0):\n",
    "    #Visualize performance of training and validation throughout training\n",
    "    print('Best Loss:', min(model.val_losses))\n",
    "    plt.close()     \n",
    "    plt.plot(model.trn_losses, label='train loss')\n",
    "    plt.plot(model.val_losses, label='val loss')\n",
    "    plt.legend()\n",
    "    plt.title('losses')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the code is done so lets test our model with different parameter settings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 6\n",
    "verb = 0\n",
    "#As in model, hidden layers have order (filters, kernel_size, stride, padding, pool)\n",
    "#filters is the number of filters in the layer,\n",
    "#the layer has kernels of shape kernel_size x kernel_size,\n",
    "#stride is the stride length in each direction\n",
    "#padding is the padding width in each direction. consider (kernel_size -1)/2\n",
    "#pool is an indicator for pooling. 0 for convolution, 1 for pooling.\n",
    "\n",
    "#filters, kernel_size, stride, padding, pool\n",
    "hidden_layers = [\n",
    "    [16,  5, 2, 2, 0],\n",
    "    [16,  3, 1, 1, 0],\n",
    "    [0,  3, 2, 1, 1],\n",
    "    [32, 3, 1, 1, 0],\n",
    "    [32, 3, 1, 1, 0],\n",
    "    [64, 3, 2, 1, 0],\n",
    "    [64, 3, 1, 1, 0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trn_images.shape, trn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = cuda(Model(images.shape[2], hidden_layers = hidden_layers, num_outputs= int(num_keys + 1)))\n",
    "x = train(trn_images, val_images, trn_df, val_df, epochs = num_epochs, verbosity = verb)\n",
    "visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets visualize the types of features the early layers of the model has learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tonumpy(model.first_layer.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code adapted from https://gist.github.com/soply/f3eec2e79c165e39c9d540e916142ae1\n",
    "def show_images(images, rows = 1, titles = None):\n",
    "    \"\"\"Display a list of images in a single figure with matplotlib.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    images: List of np.arrays compatible with plt.imshow.\n",
    "    \n",
    "    rows\n",
    "    titles: List of titles corresponding to each image. Must have\n",
    "            the same length as titles.\n",
    "    \"\"\"\n",
    "    assert((titles is None) or (len(images) == len(titles)))\n",
    "    n_images = len(images)\n",
    "    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n",
    "    fig = plt.figure()\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        a = fig.add_subplot(rows, np.ceil(n_images/float(rows)), n + 1)\n",
    "        if image.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With a normal ML dataset we should see more reasonable learned features, I don't see the model learning much with our tiny training efforts though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images([weight[0] for weight in weights], rows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
